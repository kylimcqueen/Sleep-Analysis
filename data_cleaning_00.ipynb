{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863e31e1-1276-483b-a063-8afe901314fb",
   "metadata": {},
   "source": [
    "# Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe39c6da-11af-4432-87b7-1acc9069eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "411a4259-06d0-4a2b-88b7-7cfc789b609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os #for viewing HTML in web browser\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List # If you have functions that return more than one value, \n",
    "# they will be returned in a tuple and you need this  to write that out in typehints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4355c4d9-2e0e-465d-9974-c2eaaa1b6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Pandas dataframes such that they're easy to scroll through\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f78ad555-fd6d-459c-abc8-55519ef21ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open df in the browser - easiest way to view all the data in this large dataset\n",
    "def to_html(df: pd.DataFrame) -> str:\n",
    "    '''\n",
    "    Render the df in HTML. Return the full HTML address. You can paste the HTML address in the \n",
    "    address bar to see the df at any time.\n",
    "    '''\n",
    "    df.to_html('df_view.html')\n",
    "    full_path = os.path.abspath('df_view.html')\n",
    "    print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7cd47f6-f478-42a4-bf75-8919d5816aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load file\n",
    "# work_filepath = \"C:\\\\Users\\\\kylimcqueen\\\\Downloads\\\\all_nts_animals_baseline_tall_00.csv\"\n",
    "#mac_filepath = '/Users/kyli/Desktop/Neurotrauma/all_nts_animals_baseline_tall_00.csv'\n",
    "filepath=(\"C:\\\\Users\\\\kylimcqueen\\\\Downloads\\\\all_nts_animals_postinjury_tall_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f425ddc5-d5a4-42ef-9e8c-1f24cdf02a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylimcqueen\\Downloads\\all_nts_animals_postinjury_tall_01.csv\n"
     ]
    }
   ],
   "source": [
    "#Check that we grabbed the filepath\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16708882-4271-4e84-a1c2-d163bbb9d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df\n",
    "original_df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e02da4dd-4a6c-4627-a76b-03c7f36eb059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Git\\Sleep-Analysis\\df_view.html\n"
     ]
    }
   ],
   "source": [
    "#Look at the df\n",
    "to_html(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60a0f1cf-ca2f-49a3-9d4b-d274e62e5c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41634, 12)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the datast\n",
    "original_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125736e-999f-42bf-a9ca-7e69db08c2b8",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a566424-0178-4576-a80c-f4442ff07acc",
   "metadata": {},
   "source": [
    "## Remove excluded animals\n",
    "\n",
    "We are only using data from animals in the sham vehicle and injured vehicle groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "004f3307-128d-459f-abdd-7555840d5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for excluded animals\n",
    "def whats_in_the_col(df: pd.DataFrame, data_name: str, col_name: str) -> Tuple[int, List[str]]:\n",
    "    '''\n",
    "    Counts the number of cells in the specified column of the dataframe that don't \n",
    "    exactly match the string \"Included\".\n",
    "    '''\n",
    "    assert len(df[col_name]) == len(df) #Assert we're accessing the whole column\n",
    "\n",
    "    #Assert all values in the column are of the same type (string)\n",
    "    #.map(type) gets the type of each value\n",
    "    #.nunique() counts number of unique types\n",
    "    assert df[col_name].map(type).nunique() == 1, \"Not all values are the same type\"\n",
    "                            \n",
    "    # Get values that don't match the data_name\n",
    "    non_matching_mask: list = df[col_name] != data_name\n",
    "    \n",
    "    # Count how many cells don't match\n",
    "    count: int = non_matching_mask.sum()\n",
    "    \n",
    "    # Get the actual values that don't match\n",
    "    non_matching_values: list = df.loc[non_matching_mask, col_name].unique().tolist()\n",
    "    \n",
    "    return count, non_matching_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81fb747f-2683-4701-8efd-55ab8987e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count, no_match_list = whats_in_the_col(original_df, \"Included\", \"Included\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddd344b3-1a82-4adf-8752-2f6544cb1dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count: 0.\n",
      "If count = 0 then every item in the column matches the data_name, which, for the postinjury file, is \"Included\".\n",
      "\n",
      "\n",
      " List of values that don't match the target value: []\n",
      "If no_match_list is empty, then every item in the column matches the data name, which, for the postinjury file, is \"Included\".\n"
     ]
    }
   ],
   "source": [
    "# Check that this Excel file only has animals that are included in the study (animals that lived past injury)\n",
    "\n",
    "print(f' Count: {count}.\\nIf count = 0 then every item in the column matches the data_name, which, for the postinjury file, is \"Included\".\\n\\n') \n",
    "print(f' List of values that don\\'t match the target value: {no_match_list}\\nIf no_match_list is empty, then every item in the column matches the data name, which, for the postinjury file, is \"Included\".') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1dfc6-4efa-4c62-991a-0c8fc4baa78c",
   "metadata": {},
   "source": [
    "## Remove animals given drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a3269ba-d7e7-4d9b-bb2f-3236bfade5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 24158 cells in this column that don't match the string that you searched for\n"
     ]
    }
   ],
   "source": [
    "# Check how many animals are not vehicle\n",
    "count, no_match_list = whats_in_the_col(original_df, \"vehicle\", \"Treatment\")\n",
    "print(f\" There are {count} cells in this column that don't match the string that you searched for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2abc4003-77fc-45be-9be3-ebcda4bef524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to remove animals that were treated with drug\n",
    "vehicle_df = original_df.loc[original_df['Treatment'] == 'vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b4d5b48-341d-4dd5-9f69-5203a0d28219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape: (41634, 12)\n",
      "Filtered dataframe shape: (17476, 12)\n",
      "Unique treatment values in filtered dataframe: ['vehicle']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataframe shape: {original_df.shape}\")\n",
    "print(f\"Filtered dataframe shape: {vehicle_df.shape}\")\n",
    "print(f\"Unique treatment values in filtered dataframe: {vehicle_df['Treatment'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83bb563f-346f-441f-b3ff-e5e4fa6f0153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 unique animals in the dataset.\n",
      "List of unique animals: ['C1-01' 'C1-07' 'C1-14' 'C2-04' 'C2-05' 'C2-09' 'C2-13' 'C3-04' 'C3-07'\n",
      " 'C3-10' 'C3-14' 'C4-01' 'C4-04' 'C4-06' 'C4-10' 'C4-15' 'C5-03' 'C5-11'\n",
      " 'C5-15' 'C6-02' 'C6-04' 'C6-06' 'C6-09' 'C6-11' 'C6-15' 'C7-02' 'C7-07'\n",
      " 'C7-14' 'C7-15' 'C8-05' 'C8-06' 'C8-12' 'C8-13' 'C8-16']\n"
     ]
    }
   ],
   "source": [
    "# If you want to see the list of unique animals\n",
    "unique_animals = vehicle_df['UniqueMouse'].unique()\n",
    "print(f\"There are {len(unique_animals)} unique animals in the dataset.\\nList of unique animals: {unique_animals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39117d4-71e1-4d36-838d-79164d0f9df3",
   "metadata": {},
   "source": [
    "## Handle leading and lagging NaN values\n",
    "\n",
    "Data is in [TIDY](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) format. This means each row is an observation and each column is a variable. For each different cohort, there is a certain number of NaNs at the beginning and end of sleep percent column. This is because of the way the data was originally formatted in the Excel. To address missing values, we need to get rid of all the leading and lagging NaNs and keep in mind that the number of leading and lagging Nans is the same within each cohort but different between each cohort.\n",
    "\n",
    "Note: There are 71 animals in the postinjury dataset (excluding cohort 8).\n",
    "\n",
    "Note: All UniqueMice should have 372 rows of data before trimming the leading and lagging NaNs. 372 rows per UniqueMouse * 71 UniqueMice = 26412 total rows of data, which is in agreement with the shape of the original postinjury df. Every UniqueMouse has between 300 and 400 data points and the number of datapoints is consistent within each Cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1ecac4ae-efd1-4f70-995c-a257ff48eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_nan_edges(df: pd.DataFrame, cohort_col: pd.Series, mouse_col: pd.Series, data_col:pd.Series):\n",
    "    '''\n",
    "    Get rid of the leading and lagging NaNs at the beginning and end of the set of rows that represent \n",
    "    all observations for each mouse. Do not get rid of NaNs in the middle of observations. \n",
    "    All mice within the same cohort have the same number of leading and lagging NaNs.\n",
    "    '''\n",
    "    trimmed_groups: list = []\n",
    "\n",
    "    # Nested for loop to loop over each UniqueMouse within each Cohort\n",
    "    df_grouped = df.groupby(cohort_col) # Group by Cohorts\n",
    "    for cohort_name, cohort_group in df_grouped: # Loop over each cohort    \n",
    "        for mouse_name, mouse_group in cohort_group.groupby(mouse_col): # Loop over UniqueMouse\n",
    "    \n",
    "            mouse_group = mouse_group.reset_index(drop=True) # Reset the index for the rows of a UniqueMouse\n",
    "            #print(f' The length of the mouse group is {len(mouse_group)}. The length of the mouse group should be 514 for postinjury.') testing\n",
    "            # Create a new list called valid_mask where each entry is a boolean value where T = 1 = a number and\n",
    "            # F = 0 = a NaN for that Uniquemouse's SleepPercent data\n",
    "            valid_mask = mouse_group[data_col].notna() \n",
    "\n",
    "            #If there are any NaNs\n",
    "            if valid_mask.any():\n",
    "                # first_valid_idx is the first index that returns true - the first number after leading NaNs\n",
    "                first_valid_idx = valid_mask.idxmax()\n",
    "                # last_valid_idx is the first index going backwards that returns true - the last number before lagging NaNs\n",
    "                last_valid_idx = valid_mask[valid_mask].index[-1]\n",
    "                #print(f' The number of rows in this list is {len(valid_mask)}') # Testing statement\n",
    "    \n",
    "\n",
    "                # Take the first_valid_idx and last_valid_idx, match them to corresponding actual values in the UniqueMouse\n",
    "                # SleepPercent data, and put the actual SleepPercent values in a new list called trimmed\n",
    "                trimmed = mouse_group.iloc[first_valid_idx:last_valid_idx + 1].copy() \n",
    "                #print(len(trimmed)) #Testing statement\n",
    "                # Add the trimmed SleepPercent column from one UniqueMouse to the trimmed_groups list, which is a list\n",
    "                # of trimmed values for all UniqueMice across all Cohorts\n",
    "                trimmed_groups.append(trimmed) # Add the trimmed SleepPercent column to the \n",
    "    \n",
    "    trimmed_df = pd.concat(trimmed_groups, ignore_index=True)\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fde899-e075-43b9-b5af-fa758e358249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trim_nan_edges function\n",
    "trimmed_df = trim_nan_edges(vehicle_df, \"Cohort\", \"UniqueMouse\", \"PercentSleep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2c398954-b69a-4a6c-bcaa-e8c4e41d119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Git\\Sleep-Analysis\\df_view.html\n"
     ]
    }
   ],
   "source": [
    "to_html(trimmed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2e5cc-2392-43e8-822b-6aae659287e9",
   "metadata": {},
   "source": [
    "## Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3c4cf-2ac9-402f-98c9-ea540c51eeef",
   "metadata": {},
   "source": [
    "There are multiple ways to do this. You can mask, like df[['Column name', 'Next column name', 'etc']]. \n",
    "You can use .loc to select specific parts of the df.\n",
    "\n",
    "Using .loc is likely the more stable way because when you mask it creates a something like a temporary DataFrame whose relationship to the original dataframe is unclear using a chained indexing operation. This means its not always clear whether the dataframe returned by masking is a view of the original dataframe or a copy of it. Therefore, when you try to further modify a mask of the dataframe, Pandas isn't always sure whether to modify the original or the view/copy. So you sometimes get SettingWithCopyWarnings.\n",
    "\n",
    "Using df.loc[:,columns] grabs all the rows from whatever columns you're interested in preserving. It's a single indexing operation that returns a view of the original dataframe. When you make changes with .loc, they will affect the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ebc4fda-5023-4fe2-baaf-dd5561f1f1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StudyPart', 'UniqueMouse', 'Cohort', 'InjuredGroup', 'Treatment',\n",
       "       'Included', 'Lights', 'HourOfDay', 'CumulativeHour', 'DoseMarker',\n",
       "       'PercentSleep', 'SleepBout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c6ddb30-73cf-4b59-a625-6a77fb8ac7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the relevant columns for later analysis\n",
    "relevant_cols = ['UniqueMouse', 'Cohort', 'InjuredGroup', 'Treatment','HourOfDay', 'CumulativeHour', 'PercentSleep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb3eb5-86cb-46e5-96e3-be6c4322c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "clean_df = trimmed_df.loc[:,relevant_cols]\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eabd34-64e8-4fbe-9356-50e462799ff9",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "651dd05a-4f5e-47d0-9bc0-da5ff37cde17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = clean_df.duplicated().sum()\n",
    "print(f' Number of duplicate rows: {duplicate_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83315da1-a8df-4e83-beee-4280936f9ec7",
   "metadata": {},
   "source": [
    "## Check and convert datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f363a-813d-4cdb-9a5c-2c2c5c902a65",
   "metadata": {},
   "source": [
    "### Change object datatypes to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc1ec4e0-cb9b-42df-b735-bec2cf7bed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12216 entries, 0 to 12215\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   UniqueMouse     12216 non-null  object \n",
      " 1   Cohort          12216 non-null  object \n",
      " 2   InjuredGroup    12216 non-null  object \n",
      " 3   Treatment       12216 non-null  object \n",
      " 4   HourOfDay       12216 non-null  int64  \n",
      " 5   CumulativeHour  12216 non-null  int64  \n",
      " 6   PercentSleep    12129 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 668.2+ KB\n",
      "DataFrame information: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f'DataFrame information: \\n{clean_df.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c2d32563-5524-4e60-bda3-903e65e79551",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Convert columns with type 'object' to categories because all data in these columns are limited unique values that repeat (like group identifiers).\n",
    "Category designation stores data as categorical/enumerated values, is more memory-efficient, and is faster for operations on columns.'''\n",
    "def turn_obj_cols_to_categories(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    obj_cols = df.select_dtypes(include='object').columns\n",
    "    for col in obj_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc03873-05a3-4673-9061-194a2a687ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_obj_cols_to_categories(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e1d0aa56-ae1c-45ab-991d-0eb1d79c4a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueMouse       category\n",
       "Cohort            category\n",
       "InjuredGroup      category\n",
       "Treatment         category\n",
       "HourOfDay            int64\n",
       "CumulativeHour       int64\n",
       "PercentSleep       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbe572-2a3f-4cda-b1dc-8c7a2e8bcf4e",
   "metadata": {},
   "source": [
    "# Handle all other NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db512ac-01de-4898-a005-c41726ebe982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the % of NaNs per total data for each UniqueMouse\n",
    "na_summary = clean_df[\"PercentSleep\"].isna().groupby(clean_df[\"UniqueMouse\"]).mean()\n",
    "# Print the % NaNs per total data for each UniqueMouse from largest to smallest\n",
    "print(f' There are a total of {len(na_summary)} mice.')\n",
    "print(type(na_summary.sort_values(ascending=False)))\n",
    "print(na_summary.sort_values(ascending=False))\n",
    "\n",
    "'''\n",
    "The vast majority of animals with NaN values are from Cohort 5. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0a24f-1e5a-4900-bf7a-0f1910c650ff",
   "metadata": {},
   "source": [
    "### How do we fill NaNs?\n",
    "\n",
    "Options: \n",
    "\n",
    "a. Drop them. This is likely to break analysis.\n",
    "df = df.dropna(subset=['PercentSleep'])\n",
    "\n",
    "b. Forward fill or backward fill because sleep is continuous and doesn't change abruptly.\n",
    "df['PercentSleep'] = df.groupby('UniqueMouse')['PercentSleep'].ffill().bfill() (I think choose either ffill or bfill)\n",
    "\n",
    "c. Interpolate. This is a good process to use for evenly spaced time series (ex: hourly data) because it creates a straight line between\n",
    "two adjacent data points and estimates the value between them. It considers the lienar relationshp between the known data points (Medium article)[https://medium.com/@datasciencewizards/preprocessing-and-data-exploration-for-time-series-handling-missing-values-e5c507f6c71c]\n",
    "df[\"PercentSleep\"] = df.groupby(\"UniqueMouse\")[\"PercentSleep\"].transform(lambda x: x.interpolate())\n",
    "\n",
    "d. Flag and leave. Can make a new column to flag for missingness and ealuate that later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0a65cc9f-5d65-4af6-b1a7-9427c5216c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation\n",
    "clean_df[\"PercentSleep\"] = clean_df.groupby(\"UniqueMouse\", observed=False)[\"PercentSleep\"].transform(lambda x: x.interpolate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "856482c5-c585-4368-adb1-3cc67920e235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are a total of 34 mice.\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylimcqueen\\AppData\\Local\\Temp\\ipykernel_10676\\4144121051.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  na_summary = clean_df[\"PercentSleep\"].isna().groupby(clean_df[\"UniqueMouse\"]).mean()\n"
     ]
    }
   ],
   "source": [
    "# Check that there's no NaNs now\n",
    "na_summary = clean_df[\"PercentSleep\"].isna().groupby(clean_df[\"UniqueMouse\"]).mean()\n",
    "print(f' There are a total of {len(na_summary)} mice.')\n",
    "print(type(na_summary.sort_values(ascending=False)))\n",
    "#print(na_summary.sort_values(ascending=False))\n",
    "\n",
    "#Maybe replace this with an assert statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d145282a-40c6-44fe-ad41-00ae83910446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylimcqueen\\AppData\\Local\\Temp\\ipykernel_10676\\499499547.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cohorts_dict = {cohort: data for cohort, data in clean_df.groupby('Cohort')}\n"
     ]
    }
   ],
   "source": [
    "# Make a dictionary of dataframes so that you can view each cohort independently\n",
    "# Each key is the name of the cohort (ex: C2, C3, etc) and the value is the datafarme of that cohort only\n",
    "cohorts_dict = {cohort: data for cohort, data in clean_df.groupby('Cohort')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7262e0-8e8a-42bb-a9ae-b9657cd99d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a few cohorts to make sure they look normal\n",
    "display(cohorts_dict['C7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d9bc6b9d-e05f-4a5e-8ff5-e387240a914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Git\\Sleep-Analysis\\df_view.html\n"
     ]
    }
   ],
   "source": [
    "to_html(cohorts_dict['C1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062655ea-59f5-47d6-9db3-636b75913b97",
   "metadata": {},
   "source": [
    "# Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4d858ff5-d4c7-4704-af99-515f106d1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 unique animals in the dataset after initial data cleaning\n"
     ]
    }
   ],
   "source": [
    "# Number of unique animals after data cleaning\n",
    "unique_animals = clean_df['UniqueMouse'].nunique()\n",
    "print(f'There are {unique_animals} unique animals in the dataset after initial data cleaning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53519f-e245-459a-b3e3-1860ae839f94",
   "metadata": {},
   "source": [
    "After initial data cleaning and visualization, I found that animals in cohort 5 were missing 25 hours of data.  I will drop the animals in cohort 5 becuase they are missing more than 24 hours of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87911973-afe9-4c61-85c8-bf993aa3c9ef",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0bd8d926-9266-41a2-b629-a48ce72cb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cohort 5 animals\n",
    "# The new df clean_df is equal to the old clean_df where we grouped by Cohort and took all the data where 'Cohort' is not equal to 5\n",
    "clean_df = clean_df.loc[clean_df['Cohort'] != 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d136c447-fed7-4bf0-83c3-e7ac025329b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'C5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'C5'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[201], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC5\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'C5'"
     ]
    }
   ],
   "source": [
    "print(clean_df['C5'])\n",
    "# When I return from lunch, drop cohort 5 before ceating cohorts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "541404f0-31f4-4e19-8611-4210f8896ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18713b662a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Produce interactive graphs of sleep percent per hour for each cohort using Plotly instead of Seaborn - more interactive\n",
    "\n",
    "from dash import Dash, html, dcc, Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = clean_df  \n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H4('Hourly Percent Sleep per Cohort'),\n",
    "    dcc.Graph(id=\"graph\"),\n",
    "    dcc.Checklist(\n",
    "        id=\"checklist\",\n",
    "        options=[{\"label\": cohort, \"value\": cohort} for cohort in df['Cohort'].unique()],\n",
    "        value=[df['Cohort'].unique()[0]],  # Default selected cohort(s)\n",
    "        inline=True  # Display checklist items horizontally\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"), \n",
    "    Input(\"checklist\", \"value\"))\n",
    "def update_line_chart(selected_cohorts):\n",
    "    mask = df['Cohort'].isin(selected_cohorts)\n",
    "    fig = px.line(\n",
    "        df[mask], \n",
    "        x=\"CumulativeHour\", \n",
    "        y=\"PercentSleep\", \n",
    "        color='UniqueMouse', \n",
    "        line_group='UniqueMouse',  # Group lines by each mouse\n",
    "        title=\"Hourly Percent Sleep for Selected Cohorts\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Hour of Day\",\n",
    "        yaxis_title=\"Percent Sleep\",\n",
    "        legend_title=\"Mouse ID\",\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\"  # Unified hover for better interactivity\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "40be9d0a-bcb4-4f13-af9c-71812eda0e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1871600c6b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# interactive_plot.py\n",
    "\n",
    "from dash import Dash, html, dcc, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Assumed: clean_df is already available and cleaned\n",
    "# Required columns: 'Cohort', 'UniqueMouse', 'CumulativeHour', 'PercentSleep'\n",
    "df = clean_df\n",
    "\n",
    "# User-defined color map for each cohort\n",
    "cohort_colors = {\n",
    "    'Cohort A': '#1f77b4',  # Blue\n",
    "    'Cohort B': '#ff7f0e',  # Orange\n",
    "    'Cohort C': '#2ca02c',  # Green\n",
    "    # Add more cohorts and their desired color codes here\n",
    "}\n",
    "\n",
    "# Dash styles to visually distinguish individual animals in a cohort\n",
    "dash_styles = ['solid', 'dot', 'dash', 'dashdot']\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H4('Hourly Percent Sleep per Cohort'),\n",
    "    dcc.Graph(id=\"graph\"),\n",
    "    dcc.Checklist(\n",
    "        id=\"checklist\",\n",
    "        options=[{\"label\": cohort, \"value\": cohort} for cohort in df['Cohort'].unique()],\n",
    "        value=[df['Cohort'].unique()[0]],\n",
    "        inline=True\n",
    "    ),\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"), \n",
    "    Input(\"checklist\", \"value\"))\n",
    "def update_line_chart(selected_cohorts):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for cohort in selected_cohorts:\n",
    "        cohort_df = df[df['Cohort'] == cohort]\n",
    "        mice = cohort_df['UniqueMouse'].unique()\n",
    "        base_color = cohort_colors.get(cohort, '#000000')  # fallback to black\n",
    "\n",
    "        for i, mouse in enumerate(mice):\n",
    "            mouse_df = cohort_df[cohort_df['UniqueMouse'] == mouse]\n",
    "            dash_style = dash_styles[i % len(dash_styles)]\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=mouse_df['CumulativeHour'],\n",
    "                y=mouse_df['PercentSleep'],\n",
    "                mode='lines',\n",
    "                name=f\"{cohort} - {mouse}\",\n",
    "                line=dict(color=base_color, dash=dash_style)\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Hourly Percent Sleep for Selected Cohorts\",\n",
    "        xaxis_title=\"Hour of Day\",\n",
    "        yaxis_title=\"Percent Sleep\",\n",
    "        legend_title=\"Cohort - Mouse\",\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166bf9b-66fc-46c4-880f-a9166555f85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
